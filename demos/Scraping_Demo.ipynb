{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Scraping Demo\n",
    "\n",
    "A notebook showing an example of scraping some table-based data from a city website.\n",
    "The page we're looking at is the Wilmington Civic and Neighborhood Organizations.\n",
    "We're using an html copy of the page to avoid sending a lot of bogus traffic to the city's webservers.\n",
    "Here's [the copied page](https://davidginzberg.github.io/web-scraping-with-python/practice-sites/Wilmington-Civic-Associations.html) and the original can be found on the [City of Wilmington's Website](https://www.wilmingtonde.gov/government/city-offices/constituent-services/civic-and-neighborhood-organizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing all the modules we'll be using. This should normally produce no output. On your own system you might need to `pip install bs4` before this works properly. This is automatic on mybinder.org because of the `environment.yml` file in the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_url= \"https://davidginzberg.github.io/web-scraping-with-python/practice-sites/Wilmington-Civic-Associations.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(target_url)\n",
    "if response.status_code is not 200:\n",
    "    print(\"Response code was not 200. Exiting\")\n",
    "    exit(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage_soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "print(webpage_soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the whole page, and it's a lot! let's filter it down to just the tables we saw online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = webpage_soup('table')\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_table_headers(table_list):\n",
    "    headers = list()\n",
    "    for table in table_list:\n",
    "        header = table.find(\"thead\")\n",
    "        if header is not None:  #Tables without headers cause problems without this check\n",
    "            headers.append(header.get_text(strip=True))\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Found tables with the following headers:\")\n",
    "\n",
    "for th in list_table_headers(tables):\n",
    "    print(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_header_from_table(table):\n",
    "    header = table.find(\"thead\")\n",
    "    if header is not None:\n",
    "        return header.get_text(strip=True)\n",
    "    else:\n",
    "        return \"<No table header>\"\n",
    "\n",
    "def list_of_fields_from_rows(row_list):\n",
    "    field_list = list()\n",
    "    for row in row_list:\n",
    "        cells = row.find_all('td')\n",
    "        #This assumes a 2-colunn table. Really only designed for the page we're working on\n",
    "        if len(cells) is 2:\n",
    "            field_list.append( \n",
    "                ( cells[0].get_text(), cells[1].get_text() ) \n",
    "            )\n",
    "    return field_list\n",
    "\n",
    "def build_table_dicts(table_list):\n",
    "    table_dicts = list()\n",
    "    for table in table_list:\n",
    "        t_dict = dict()\n",
    "        #From each table we want the header and all the fields (and their values)\n",
    "        t_dict[\"title\"] = get_header_from_table(table)\n",
    "        #Add the fields to the dictionary\n",
    "        t_dict[\"fields\"] = list_of_fields_from_rows(table)\n",
    "        #Add the dictionary of the current table to the list\n",
    "        table_dicts.append(t_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to see the object types you're dealing with in Python? Try this next snippet. You don't need this to be able to scrape a page, but I found it useful during debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for table in tables:\n",
    "     print(f\"Table of type: {type(table)}\")\n",
    "     for row in table.find_all('tr'):\n",
    "         print(f\"Row of type: {type(row)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
